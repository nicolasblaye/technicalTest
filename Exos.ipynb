{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Interview\n",
    "\n",
    "This document presents notes and codes about 3 exercices. The code will be in python 2, the data is given in a separate csv (too big for github).\n",
    "\n",
    "The data were extract from two compressed files. The files were corrupted so I had to use `bzip2recover` to uncompress them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "### Task: count the number of lines in Python for each file\n",
    "\n",
    "We use a csv reader to iterate over the whole file, using a small counter to count the number of (not empty) lines.\n",
    "Reading the whole file with `f.read()` won't work because of the size of the files.\n",
    "We found 20 390 199 lines for **searches.csv** and 10 000 011 lines for **bookings.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_searches = 20390199 lines\n",
      "nb_bookings = 10000011 lines\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"./data/searches.csv\",\"r\") as f:\n",
    "    reader = csv.reader(f,delimiter=\"^\")\n",
    "    i = 0\n",
    "    for row in reader:\n",
    "        if row!=\"\\n\" and row!=\"\":\n",
    "            i +=1\n",
    "    print \"nb_searches = %d lines\"%i\n",
    "with open(\"./data/bookings.csv\",\"r\") as f:\n",
    "    reader = csv.reader(f,delimiter=\"^\")\n",
    "    i = 0\n",
    "    for row in reader:\n",
    "        if row!=\"\\n\" and row!=\"\":\n",
    "            i +=1\n",
    "    print \"nb_bookings = %d lines\"%i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "### Task: top 10 arrival airports in the world in 2013 (using the bookings file)\n",
    "\n",
    "We use a smaller version of bookings.csv for testing. That way,  we can open it with *libre office* to better understand the data and also make faster test. To make this file, we use `head` function and redirect the result to **bookings_head.csv**.  \n",
    "First, we map all the flight where `duration + off time` is prior to 2014 and after 2012. Then, we reduce all the previous result by adding the pax column and we get the first ten airports. At last, we use **GeoBase** to get the name of the airport.  \n",
    "We find that we need to chunk the file, aggregate the data by airport, then merge the results.\n",
    "There was a null value on one column, so we use `dropna` to drop any row that does not have information on `arr_port`, `pax`, `off_time` or `duration`.  \n",
    "There are still values that cannot be interpreted. It is because we can have a string instead of an int in `duration` (like 'NRT') and also some float that can not be interpreted as float because it has a floating commas intead of the standart point. We handle that by adding NRT to the na_values, and by setting the commas as a decimal separator.  \n",
    "  \n",
    "| rank |  arr_port_code |         arr_port_name       |  pax |\n",
    "|------|:--------------:|:---------------------------:|------|\n",
    "|0     | LHR            | London Heathrow Airport     | 81439.0|\n",
    "|1      |LAX          |Los Angeles International Airport | 64230.0|\n",
    "|2      |LAS           |  McCarran International Airport | 63190.0|\n",
    "|3      |MCO            |  Orlando International Airport | 62290.0|\n",
    "|4      |JFK       |John F Kennedy International Airport | 60060.0|\n",
    "|5      |CDG        |          Paris - Charles-de-Gaulle | 58080.0|\n",
    "|6      |SFO        |San Francisco International Airport | 53710.0|\n",
    "|7      |MIA         |       Miami International Airport | 53020.0|\n",
    "|8      |BKK          |                     Suvarnabhumi | 52660.0|\n",
    "|9      |DXB           |     Dubai International Airport | 52230.0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  arr_port_code                         arr_port_name      pax\n",
      "0      LHR                    London Heathrow Airport  81439.0\n",
      "1      LAX          Los Angeles International Airport  64230.0\n",
      "2      LAS             McCarran International Airport  63190.0\n",
      "3      MCO              Orlando International Airport  62290.0\n",
      "4      JFK       John F Kennedy International Airport  60060.0\n",
      "5      CDG                  Paris - Charles-de-Gaulle  58080.0\n",
      "6      SFO        San Francisco International Airport  53710.0\n",
      "7      MIA                Miami International Airport  53020.0\n",
      "8      BKK                               Suvarnabhumi  52660.0\n",
      "9      DXB                Dubai International Airport  52230.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from GeoBases import GeoBase\n",
    "\n",
    "def process(chunk):\n",
    "    \n",
    "    # take the useful columns\n",
    "    data = chunk[['arr_port','pax','off_time           ','duration']]\n",
    "    \n",
    "    # supress NaN rows and change ',' to '.' for float conversion\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # convert off_time column from string to datetime\n",
    "    off_time = data['off_time           ']\n",
    "    off_time = pd.to_datetime(off_time)\n",
    "    off_time = off_time.astype(np.int64)\n",
    "\n",
    "\n",
    "    # filter the column where duration + off_time < 2014 and off_time+duration >= 2013\n",
    "    arrival = pd.to_datetime(off_time+data['duration'])\n",
    "    data = data[arrival < pd.to_datetime(\"2014-1-1\")]\n",
    "    data = data[arrival >= pd.to_datetime(\"2013-1-1\")]\n",
    "\n",
    "    # group the number of passenger by airport name\n",
    "    arrival = data.groupby('arr_port').sum()    \n",
    "    return arrival\n",
    "            \n",
    "arr_data = dict() \n",
    "#processing the csv_file in chunks\n",
    "chunksize = 10 ** 3\n",
    "i = 0\n",
    "for chunk in pd.read_csv(\"./data/bookings.csv\", delimiter=\"^\", iterator=True, chunksize=chunksize,\n",
    "                        na_values = ['NRT     '], decimal=\",\"):\n",
    "    data = process(chunk)\n",
    "    for key,value in data['pax'].iteritems():\n",
    "        if key not in arr_data:\n",
    "            arr_data[key] = 0\n",
    "        arr_data[key] += value\n",
    "\n",
    "# order the result in a list of tuple\n",
    "arr_data = sorted(arr_data.items(), key=lambda x:x[1], reverse = True)\n",
    "\n",
    "# use geobase to get the name of the 10 best airports\n",
    "geo_a = GeoBase(data='airports', verbose=False)\n",
    "result = []\n",
    "for i in range(10):  \n",
    "    name = geo_a.get(arr_data[i][0].strip(),\"name\")\n",
    "    result.append((arr_data[i][0],name, arr_data[i][1]))\n",
    "\n",
    "print pd.DataFrame(result,columns=['arr_port_code','arr_port_name','pax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "### Task: plot the monthly number of searches for flights arriving at MÃ¡laga, Madrid or Barcelona\n",
    "\n",
    "We then again use a smaller version of searches.csv to make our base functions work. Then we chunk the file to first map the wanted destination and reduce it to reduce memory usage.\n",
    "Malaga airport is AGP\n",
    "Madrid airport is MAD\n",
    "Barcelona airpot is BCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dt = pd.read_csv(\"searches_head.csv\",delimiter=\"^\")\n",
    "grouped = pd.groupby(\"Destination\")\n",
    "print grouped.groups[\"MAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
